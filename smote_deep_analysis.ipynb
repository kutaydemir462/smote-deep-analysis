{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980d613e-44f4-4986-82a7-3e65008709e9",
   "metadata": {},
   "source": [
    "# SMOTE Deep Analysis - Oversampling Techniques for Imbalanced Fraud Data (No Modeling)\n",
    "\n",
    "### What This Notebook Covers\n",
    "This notebook is a **visual and conceptual exploration** of oversampling techniques for imbalanced datasets,  \n",
    "using the **Credit Card Fraud dataset** (creditcard.csv from Kaggle).  \n",
    "\n",
    "I do **not train models** here. Instead, the focus is on understanding **how different oversampling methods reshape the dataset**  \n",
    "and what these changes mean for downstream modeling.\n",
    "\n",
    "### Pipeline\n",
    "1. **SMOTE (Regular)** — synthetic samples between minority neighbors  \n",
    "2. **Random Oversampling (ROS)** — simple duplication of minority class  \n",
    "3. **Borderline-SMOTE (1 & 2)** — focus on decision boundary (“danger zone”)  \n",
    "4. **KMeans-SMOTE** — cluster-based adaptive oversampling  \n",
    "\n",
    "### Goal\n",
    "- Show **class counts** before & after each technique  \n",
    "- Visualize how each method changes the **data distribution**  \n",
    "- Provide **practical guidance** on when to use each oversampling method  \n",
    "\n",
    "By the end, you’ll have a clear **intuition** of how oversampling works without running a single model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe453a-98e6-408c-acfb-a47ae62f09db",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "Creates synthetic minority samples by interpolating between a sample and its nearest minority neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd386deb-330c-496f-a2c2-f5fa3a59f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TRAIN distribution: Counter({0: 227451, 1: 394})\n",
      "\n",
      "[sampling_strategy=0.1, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 22745})\n",
      "\n",
      "[sampling_strategy=0.1, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 22745})\n",
      "\n",
      "[sampling_strategy=0.1, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 22745})\n",
      "\n",
      "[sampling_strategy=0.1, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 22745})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=not majority, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=not majority, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=not majority, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=not majority, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=all, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=all, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=all, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=all, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=10]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"data/creditcard.csv\"\n",
    "TARGET_COL = \"Class\"\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "# split so I don't oversample test (I'll look only at train)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Original TRAIN distribution:\", Counter(ytr))\n",
    "\n",
    "# define parameter grids\n",
    "sampling_list = [0.1, 0.25, 0.5, 1.0, 'minority', 'not majority', 'all']\n",
    "smote_k_list = [3, 5, 7, 10]\n",
    "\n",
    "# dict example: force minority to be ~80% of majority\n",
    "dict_target = {1: int(0.8 * Counter(ytr)[0])}\n",
    "sampling_list.append(dict_target)\n",
    "\n",
    "# try combos and show class counts\n",
    "for ss in sampling_list:\n",
    "    for sk in smote_k_list:\n",
    "        try:\n",
    "            sm = SMOTE(sampling_strategy=ss, k_neighbors=sk, random_state=42)\n",
    "            X_res, y_res = sm.fit_resample(Xtr, ytr)\n",
    "            print(f\"\\n[sampling_strategy={ss}, k_neighbors={sk}]\")\n",
    "            print(\" Resampled distribution:\", Counter(y_res))\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[sampling_strategy={ss}, k_neighbors={sk}] -> ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44ec13-17ce-43f8-b577-77dcd8490696",
   "metadata": {},
   "source": [
    "### Analysis of SMOTE Parameter Experiments\n",
    "\n",
    "**Original train distribution:**  \n",
    "- Majority (0): **227,451**  \n",
    "- Minority (1): **394** → extremely imbalanced.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. sampling_strategy (float values)\n",
    "- **0.1** → minority = 22,745 (≈10% of majority)  \n",
    "- **0.25** → minority = 56,862 (≈25% of majority)  \n",
    "- **0.5** → minority = 113,725 (≈50% of majority)  \n",
    "- **1.0** → minority = 227,451 (balanced 1:1)  \n",
    "\n",
    "Floats directly control the **ratio** of minority to majority after resampling.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. sampling_strategy (string values)\n",
    "- 'minority', 'not majority', 'all' → all ended up balancing the classes (**227,451 vs 227,451**).  \n",
    "\n",
    "In binary problems, these string options all act like 1.0.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. k_neighbors\n",
    "- Tried 3, 5, 7, 10 → **counts did not change**.  \n",
    "- This parameter affects **where the synthetic samples are generated**:  \n",
    "  - Small k → local interpolation (tighter clusters).  \n",
    "  - Large k → smoother, more spread out synthetic points (but can risk crossing into majority space).\n",
    "\n",
    "k_neighbors changes the **geometry**, not the **number** of samples.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. sampling_strategy (dict example)\n",
    "- {1: 181960} → minority forced to exactly 181,960 samples.  \n",
    "- Majority stayed 227,451 → ratio ≈ 0.8.  \n",
    "\n",
    "Dict gives **absolute control** over final class sizes, independent of ratios.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusions\n",
    "- **sampling_strategy** = decides **how many synthetic points**.  \n",
    "- **k_neighbors** = decides **where synthetic points are placed**.  \n",
    "- **dict** = lets you hard-set target counts.  \n",
    "- On creditcard data, I can scale minority from a few hundred → hundreds of thousands just by changing the parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496dca6d-a9cd-4344-95ae-6e6cf23f503c",
   "metadata": {},
   "source": [
    "### SMOTE API mini-experiments (why & what to expect)\n",
    "\n",
    "**fit(X, y)**  \n",
    "- Only validates inputs and computes internal stats (e.g., neighbor index).  \n",
    "\n",
    "**fit_resample(X, y)**  \n",
    "- Does everything `fit` does **and** returns `(X_resampled, y_resampled)`.  \n",
    "\n",
    "**get_feature_names_out(input_features=None)**  \n",
    "- Returns feature names for the output.  \n",
    "- If X is a DataFrame with string column names, you’ll get them back. Otherwise it falls back to **[\"x0\", \"x1\", ...]**.\n",
    "\n",
    "**get_params**(deep=True) / set_params(**kwargs)**  \n",
    "- Standard sklearn-style param access/update.  \n",
    "- Useful to **log** the config you ran, or to change **k_neighbors** / **sampling_strategy** \n",
    "\n",
    "**get_metadata_routing()**  \n",
    "- Advanced plumbing for scikit-learn’s metadata routing.  \n",
    "- Not needed for normal SMOTE use, but you can call it and see the object returned.\n",
    "\n",
    "### What is get_metadata_routing()?\n",
    "This is an internal utility in scikit-learn for **advanced pipelines**. It controls how extra information (metadata like sample_weight or groups) flows between different steps.  \n",
    "For SMOTE we don’t need it at all, since SMOTE only uses X and y. We can ignore it safely, it’s just part of scikit-learn’s plumbing.\n",
    "\n",
    "**What we’ll do now**  \n",
    "1) Inspect params → 2) call fit (no resample) → 3) call fit_resample and check counts → 4) change params with set_params and resample again → 5) try get_feature_names_out and get_metadata_routing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69ac32b-d8f9-40ac-b4ca-34c2bca15be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TRAIN distribution: Counter({0: 227451, 1: 394})\n",
      "\n",
      "get_params (short): {'sampling_strategy': 0.25, 'k_neighbors': 5, 'random_state': 42}\n",
      "fit() done (no resampling returned).\n",
      "After fit_resample with sampling_strategy=0.25, k_neighbors=5 -> Counter({0: 227451, 1: 56862})\n",
      "After set_params(k=7, ss=0.5) -> Counter({0: 227451, 1: 113725})\n",
      "\n",
      "get_feature_names_out (first 10): ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9'] …\n",
      "get_metadata_routing() type: MetadataRequest\n"
     ]
    }
   ],
   "source": [
    "# SMOTE API mini-experiments (no modeling) \n",
    "CSV_PATH = \"data/creditcard.csv\"\n",
    "TARGET_COL = \"Class\"\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#load + split\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Original TRAIN distribution:\", Counter(ytr))\n",
    "\n",
    "#create SMOTE and inspect params\n",
    "sm = SMOTE(sampling_strategy=0.25, k_neighbors=5, random_state=42)\n",
    "print(\"\\nget_params (short):\", {k: sm.get_params()[k] for k in ['sampling_strategy','k_neighbors','random_state']})\n",
    "\n",
    "#fit() only (no resample) — just to show it runs\n",
    "sm.fit(Xtr, ytr)\n",
    "print(\"fit() done (no resampling returned).\")\n",
    "\n",
    "#fit_resample() — actual resampling\n",
    "X_res, y_res = sm.fit_resample(Xtr, ytr)\n",
    "print(\"After fit_resample with sampling_strategy=0.25, k_neighbors=5 ->\", Counter(y_res))\n",
    "\n",
    "#set_params() — change k_neighbors and sampling_strategy, resample again\n",
    "sm.set_params(k_neighbors=7, sampling_strategy=0.5)\n",
    "X_res2, y_res2 = sm.fit_resample(Xtr, ytr)\n",
    "print(\"After set_params(k=7, ss=0.5) ->\", Counter(y_res2))\n",
    "\n",
    "#feature names out\n",
    "try:\n",
    "    names = sm.get_feature_names_out(getattr(Xtr, 'columns', None))\n",
    "    print(\"\\nget_feature_names_out (first 10):\", list(names)[:10], \"…\")\n",
    "except Exception as e:\n",
    "    print(\"\\nget_feature_names_out -> ERROR:\", e)\n",
    "\n",
    "#metadata routing (just to see it's there)\n",
    "try:\n",
    "    routing = sm.get_metadata_routing()\n",
    "    print(\"get_metadata_routing() type:\", type(routing).__name__)\n",
    "except Exception as e:\n",
    "    print(\"get_metadata_routing -> ERROR:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91cc03-c7c6-4c2f-9ab5-95894c0344fe",
   "metadata": {},
   "source": [
    " ## Random Oversampling (ROS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95726ec-d817-4069-a38f-4b8b40890818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ROS: Counter({0: 284315, 1: 492})\n",
      "After ROS: Counter({0: 284315, 1: 284315})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print(\"Before ROS:\", Counter(y))\n",
    "print(\"After ROS:\", Counter(y_ros))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60494a56-913f-401b-8d81-7767d1e1911c",
   "metadata": {},
   "source": [
    "### Random Oversampling (ROS)\n",
    "\n",
    "Random Oversampling is the most straightforward balancing technique.  \n",
    "Instead of generating synthetic samples, it simply **duplicates existing minority class samples** until the dataset is balanced.  \n",
    "\n",
    "- **Before ROS:** 0 : 284,315 | 1 : 492  \n",
    "- **After ROS:** 0 : 284,315 | 1 : 284,315\n",
    "\n",
    "**Pros:**  \n",
    "- Very simple and effective at balancing.  \n",
    "- Ensures the minority class has equal representation.  \n",
    "\n",
    "**Cons:**  \n",
    "- Can cause **overfitting**, since the model may see the same minority examples multiple times.  \n",
    "- Doesn’t add new information like SMOTE or Borderline-SMOTE.  \n",
    "\n",
    "ROS serves as a **baseline** method to compare with more advanced oversampling techniques (SMOTE, Borderline-SMOTE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee8a44-d89a-4835-995c-7131344db308",
   "metadata": {},
   "source": [
    "## BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b43ba61-d7f2-45aa-9c23-cc62353b3c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TRAIN distribution: Counter({0: 227451, 1: 394})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=3, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=5, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.25, k_neighbors=7, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56862})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=3, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=5, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=0.5, k_neighbors=7, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113725})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=3, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=5, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=1.0, k_neighbors=7, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=3, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=5, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy=minority, k_neighbors=7, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 227451})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=3, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=5, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7, m_neighbors=5, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7, m_neighbors=5, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7, m_neighbors=10, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7, m_neighbors=10, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7, m_neighbors=15, kind=borderline-1]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n",
      "\n",
      "[sampling_strategy={1: 181960}, k_neighbors=7, m_neighbors=15, kind=borderline-2]\n",
      " Resampled distribution: Counter({0: 227451, 1: 181960})\n"
     ]
    }
   ],
   "source": [
    "# BorderlineSMOTE parameter experiments: print class counts only \n",
    "CSV_PATH = \"data/creditcard.csv\"   # Kaggle credit card fraud dataset\n",
    "TARGET_COL = \"Class\"\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# 1) load + split (resample ONLY on train)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Original TRAIN distribution:\", Counter(ytr))\n",
    "\n",
    "# 2) parameter grids\n",
    "# sampling_strategy: floats (ratio minority/majority), strings, and a dict example\n",
    "sampling_list = [0.25, 0.5, 1.0, 'minority']  # keep it short\n",
    "dict_target = {1: int(0.8 * Counter(ytr)[0])}  # force minority ≈ 80% of majority\n",
    "sampling_list.append(dict_target)\n",
    "\n",
    "k_list = [3, 5, 7]        # k_neighbors: synthesis neighborhood\n",
    "m_list = [5, 10, 15]      # m_neighbors: \"danger\" neighborhood\n",
    "kinds = ['borderline-1', 'borderline-2']\n",
    "\n",
    "# 3) run and print counts\n",
    "for ss in sampling_list:\n",
    "    for k in k_list:\n",
    "        for m in m_list:\n",
    "            for kd in kinds:\n",
    "                try:\n",
    "                    bls = BorderlineSMOTE(\n",
    "                        sampling_strategy=ss,\n",
    "                        k_neighbors=k,\n",
    "                        m_neighbors=m,\n",
    "                        kind=kd,\n",
    "                        random_state=42\n",
    "                    )\n",
    "                    X_res, y_res = bls.fit_resample(Xtr, ytr)\n",
    "                    print(f\"\\n[sampling_strategy={ss}, k_neighbors={k}, m_neighbors={m}, kind={kd}]\")\n",
    "                    print(\" Resampled distribution:\", Counter(y_res))\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n[sampling_strategy={ss}, k_neighbors={k}, m_neighbors={m}, kind={kd}] -> ERROR: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594e328-a01c-41de-9b1f-c77325a7f2a5",
   "metadata": {},
   "source": [
    "### Analysis of BorderlineSMOTE Parameter Experiments\n",
    "\n",
    "**Original train distribution:**  \n",
    "- Majority (0): **227,451**  \n",
    "- Minority (1): **394** → extremely imbalanced.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. sampling_strategy\n",
    "- **0.25** → minority scaled to ~56,862 (≈25% of majority).  \n",
    "- **0.5** → minority scaled to ~113,725 (≈50% of majority).  \n",
    "- **1.0** → fully balanced at 227,451 vs 227,451.  \n",
    "- **'minority'** → same as 1.0 (balances the dataset).  \n",
    "- **dict {1: 181960}** → minority forced to exactly 181,960 (≈80% of majority).  \n",
    "\n",
    "Same pattern as classic SMOTE: sampling_strategy **controls the final counts**, regardless of other parameters.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. k_neighbors\n",
    "- Tested 3, 5, 7 → **class counts stayed the same**.  \n",
    "- Like in SMOTE, this parameter controls **where synthetic samples are generated**, not how many.  \n",
    "- Smaller k → more local interpolation.  \n",
    "- Larger k → more spread-out neighbors.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. m_neighbors\n",
    "- Tried 5, 10, 15 → **no change in counts** either.  \n",
    "- **m_neighbors** controls how “danger” samples (minority points near the majority) are detected.  \n",
    "- Affects **which minority samples are oversampled**, not the final count.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. kind (borderline-1 vs borderline-2)\n",
    "- Both **borderline-1** and **borderline-2** gave **identical distributions** in terms of counts.  \n",
    "- The difference is *which minority points* are chosen:\n",
    "  - **borderline-1**: only uses “danger” samples (minority points close to majority) to generate new ones.  \n",
    "  - **borderline-2**: uses both “danger” and some majority-adjacent points, generating slightly more diverse synthetic data.  \n",
    "- The effect is **qualitative (geometry of samples)**, not quantitative (counts).\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusions\n",
    "- **sampling_strategy**: the only parameter that changes **how many synthetic samples** are created.  \n",
    "- **k_neighbors**: defines the interpolation neighborhood, influences the **distribution shape** of synthetic samples.  \n",
    "- **m_neighbors**: defines how we detect borderline/danger points, again affects *where* new points are made.  \n",
    "- **kind**: changes the algorithm’s definition of “borderline” (1 vs 2) but **not the class counts**.  \n",
    "\n",
    "On our dataset, counts didn’t change with `k_neighbors`, `m_neighbors`, or `kind` → but the **quality/placement** of the synthetic minority points *did* change internally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc18e86-9642-4cd6-99fb-b68b58b21c39",
   "metadata": {},
   "source": [
    "### What is m_neighbors in BorderlineSMOTE?\n",
    "\n",
    "- BorderlineSMOTE focuses on **“danger” minority samples** → these are minority points that sit close to majority points (on the decision boundary).\n",
    "- Why? Because misclassifications usually happen at the boundary, so oversampling there is more useful than duplicating safe points.\n",
    "\n",
    "---\n",
    "\n",
    "#### Role of m_neighbors\n",
    "- **m_neighbors** = how many neighbors we check around each minority point to decide if it’s:\n",
    "  - **Safe** → mostly surrounded by other minority points (no need to oversample).\n",
    "  - **Danger** → surrounded by many majority points (good candidate to oversample).\n",
    "  - **Noise** → completely surrounded by majority (ignored, not oversampled).\n",
    "\n",
    "---\n",
    "\n",
    "#### Why it helps\n",
    "- If **m_neighbors** is **small (e.g., 5)** → danger zones are detected very locally. More points are labeled as “danger,” which means more synthetic samples, but also risk of adding noise.\n",
    "- If **m_neighbors** is **large (e.g., 15)** → danger detection is stricter. Fewer points are marked as danger, so fewer but cleaner synthetic samples are created.\n",
    "\n",
    "---\n",
    "\n",
    "###  Takeaway\n",
    "- **m_neighbors controls how sensitive BorderlineSMOTE is when finding borderline points.**\n",
    "- It doesn’t change how many samples are generated overall (that’s sampling_strategy), but it changes **which minority points** are used to generate them.\n",
    "- The “best” value depends on the dataset → small values oversample more aggressively, large values oversample more carefully.\n",
    "\n",
    "Without SMOTE → the model is biased toward majority, ignores minority.\n",
    "\n",
    "With BorderlineSMOTE → synthetic minority samples fill in the “hard-to-learn” boundary zones.\n",
    "\n",
    "This teaches the model to recognize fraud better, instead of just predicting “not fraud” all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d2e0b-bc6c-4b7b-9fc5-e84abb994c41",
   "metadata": {},
   "source": [
    "![m_neighbors](example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7247d14-4a05-4d54-ba5c-dac21d5a5593",
   "metadata": {},
   "source": [
    "BorderlineSMOTE focuses on the orange “danger” points and generates synthetic samples around them to strengthen the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f6ea8-62e3-4c1b-b7de-3500d44cc791",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE — kind parameter\n",
    "\n",
    "BorderlineSMOTE has two algorithm variants: **borderline-1** and **borderline-2**.  \n",
    "Both focus on oversampling the **danger samples** (minority points close to majority points), but they handle the neighborhood slightly differently:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. borderline-1\n",
    "- Only oversamples **danger minority samples**.  \n",
    "- Generates new synthetic points **between the danger sample and its minority neighbors**.  \n",
    "- Goal: reinforce the minority exactly where it’s under threat from the majority.  \n",
    "- More conservative → sticks closer to existing minority points.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. borderline-2\n",
    "- Also oversamples danger samples, **but**:  \n",
    "- Generates synthetic points not only towards other minority neighbors, but also **towards majority neighbors**.  \n",
    "- This spreads synthetic samples wider, covering the whole boundary area.  \n",
    "- More aggressive → can help when classes overlap strongly, but may risk creating noisier samples.\n",
    "\n",
    "---\n",
    "\n",
    "### Takeaway\n",
    "- **Both kinds** create the same *number* of samples (controlled by **sampling_strategy**), but they differ in *where* the new points are placed.  \n",
    "- **borderline-1** → safer, tighter oversampling around existing minority.  \n",
    "- **borderline-2** → wider oversampling, may better handle overlaps but can introduce more noise.  \n",
    "- Which one works better depends on the dataset → you typically try both and compare model performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6722785a-4728-4ea9-be4a-e80009ee1e83",
   "metadata": {},
   "source": [
    "![borderline-1](borderline-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2f677-d6bc-4363-826e-50b4d6015026",
   "metadata": {},
   "source": [
    "![borderline-2](borderline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7c426-4e1f-41de-9261-75c7cf102989",
   "metadata": {},
   "source": [
    "## KMeans SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c057b73-b14a-4c47-9754-2a2908a3c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TRAIN distribution: Counter({0: 227451, 1: 394})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kutayd\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=16\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[sampling_strategy=0.25, k_neighbors=2, kmeans_k=12, cluster_balance_threshold=0.0, density_exponent=auto]\n",
      " Resampled distribution: Counter({0: 227451, 1: 56872})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kutayd\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=16\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[sampling_strategy=0.5, k_neighbors=2, kmeans_k=12, cluster_balance_threshold=0.0, density_exponent=auto]\n",
      " Resampled distribution: Counter({0: 227451, 1: 113734})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kutayd\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=16\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[sampling_strategy=1.0, k_neighbors=2, kmeans_k=12, cluster_balance_threshold=0.0, density_exponent=auto]\n",
      " Resampled distribution: Counter({1: 227460, 0: 227451})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kutayd\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=16\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[sampling_strategy=minority, k_neighbors=2, kmeans_k=12, cluster_balance_threshold=0.0, density_exponent=auto]\n",
      " Resampled distribution: Counter({1: 227460, 0: 227451})\n"
     ]
    }
   ],
   "source": [
    "# Robust KMeansSMOTE run on creditcard.csv: print class counts only \n",
    "\n",
    "CSV_PATH = \"data/creditcard.csv\"\n",
    "TARGET_COL = \"Class\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "\n",
    "# (Windows MKL tip) Reduce threads to avoid the MiniBatchKMeans warning\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"4\")\n",
    "\n",
    "# 1) load + split\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Original TRAIN distribution:\", Counter(ytr))\n",
    "\n",
    "# choose conservative, workable params for extreme imbalance\n",
    "# - few clusters so each cluster has several minority points\n",
    "# - k_neighbors=2 (default)\n",
    "# - cluster_balance_threshold relaxed to 0.0\n",
    "# - pass MiniBatchKMeans with large batch_size to avoid warning\n",
    "minority_count = Counter(ytr)[1]\n",
    "n_clusters = max(5, min(12, minority_count // 20))  # heuristic: aim ~≥20 minority per cluster\n",
    "\n",
    "kmeans_obj = MiniBatchKMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    batch_size=4096,   # >= 3584 to avoid MKL warning; adjust if needed\n",
    "    n_init=\"auto\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "configs = [\n",
    "    # (sampling_strategy, k_neighbors, cluster_balance_threshold, density_exponent)\n",
    "    (0.25, 2, 0.0, \"auto\"),\n",
    "    (0.50, 2, 0.0, \"auto\"),\n",
    "    (1.00, 2, 0.0, \"auto\"),\n",
    "    (\"minority\", 2, 0.0, \"auto\"),\n",
    "]\n",
    "\n",
    "for ss, kn, cbt, dexp in configs:\n",
    "    try:\n",
    "        kms = KMeansSMOTE(\n",
    "            sampling_strategy=ss,\n",
    "            k_neighbors=kn,\n",
    "            kmeans_estimator=kmeans_obj,\n",
    "            cluster_balance_threshold=cbt,\n",
    "            density_exponent=dexp,\n",
    "            random_state=42\n",
    "        )\n",
    "        X_res, y_res = kms.fit_resample(Xtr, ytr)\n",
    "        print(f\"\\n[sampling_strategy={ss}, k_neighbors={kn}, kmeans_k={n_clusters}, \"\n",
    "              f\"cluster_balance_threshold={cbt}, density_exponent={dexp}]\")\n",
    "        print(\" Resampled distribution:\", Counter(y_res))\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ss={ss}, kn={kn}, kmeans_k={n_clusters}, cbt={cbt}, dexp={dexp}] -> ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c78c5c-8bba-4540-b533-36ff150dd0f7",
   "metadata": {},
   "source": [
    "### KMeansSMOTE — What your output shows & what each parameter did\n",
    "\n",
    "**Original TRAIN distribution:**  \n",
    "- Majority (0): **227,451**  \n",
    "- Minority (1): **394**  → extremely imbalanced.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1) sampling_strategy (changed): **controls how many minority samples are created**\n",
    "Your runs:\n",
    "\n",
    "- *sampling_strategy = 0.25** → **1 ≈ 56,872** vs 0 = 227,451  \n",
    "- **sampling_strategy = 0.5**  → **1 ≈ 113,734** vs 0 = 227,451  \n",
    "- **sampling_strategy = 1.0**  → **1 ≈ 227,460** vs 0 = 227,451 (balanced, tiny off-by-few)  \n",
    "- **sampling_strategy = \"minority\"** → **1 ≈ 227,460** vs 0 = 227,451 (same as 1.0 for binary)\n",
    "\n",
    "**Why the small mismatch (227,460 vs 227,451)?**  \n",
    "KMeansSMOTE allocates synthetic samples **per cluster**. After rounding per-cluster quotas, the final minority count can differ by a few samples from the “exact” target—this is normal.\n",
    "\n",
    "**Takeaway:** **sampling_strategy** is the **only** thing changing the **counts**. All other params affect **where** new points go, not how many.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) k_neighbors = 2 (fixed in your runs): **local interpolation inside clusters**\n",
    "- Controls how SMOTE interpolates **within each cluster** (how “local” the synthesis is).  \n",
    "- Does **not** change counts; only the geometry/placement of synthetic samples.  \n",
    "- With very few minority per cluster, small values (2–3) are safer.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) kmeans_k = 12 : **how finely we partition the space**\n",
    "- KMeansSMOTE first clusters the data, then oversamples **within** clusters that contain enough minority.  \n",
    "- More clusters = finer regions, but **risk** empty/single-minority clusters (can’t interpolate).  \n",
    "- Fewer clusters = coarser regions, often **more stable** with tiny minority (like this dataset).  \n",
    "- Your choice of **12** worked (we didn't get the error this time “not enough minority in any cluster”).\n",
    "\n",
    "---\n",
    "\n",
    "#### 4) cluster_balance_threshold = 0.0 : **which clusters are eligible**\n",
    "- With **0.0**, we essentially **allow all clusters** to be considered for oversampling.  \n",
    "- If this threshold is too **strict** (e.g., **'auto'** on a dataset with ultra-few minority), many clusters get excluded → we can get **“No clusters found…”** errors.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5) density_exponent = \"auto\": **how per-cluster density weights are computed**\n",
    "- Used to **distribute** the total number of synthetic samples **across clusters** (denser clusters may get more samples).  \n",
    "- Doesn’t change overall counts, only **where** samples are allocated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283b8da-7e1d-4c20-9a7e-233fb76bcd95",
   "metadata": {},
   "source": [
    "![kmeans](kmeans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccad42-e54d-4237-8609-3fb35cf19078",
   "metadata": {},
   "source": [
    "## 1. Why KMeans before SMOTE?\n",
    "- Standard **SMOTE** creates synthetic minority samples by interpolating between neighbors, but it doesn’t consider the global structure of the data.  \n",
    "- This can generate unrealistic samples in areas where majority and minority overlap.  \n",
    "- **KMeans-SMOTE** first clusters the dataset → oversampling happens *within each cluster* instead of across the whole dataset.  \n",
    "- Result: synthetic samples are **more realistic and cluster-aware**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How It Works Step by Step\n",
    "1. **Clustering**  \n",
    "   - Data is divided into clusters (**kmeans_k** = number of clusters).  \n",
    "   - Each cluster has its own mix of majority and minority points.  \n",
    "\n",
    "2. **Cluster Selection**  \n",
    "   - Clusters with **higher minority ratios** get more oversampling.  \n",
    "   - Clusters dominated by majority get less (or none) to avoid noisy samples.  \n",
    "\n",
    "3. **Sample Creation**  \n",
    "   - Within chosen clusters, SMOTE generates new points by interpolating between minority neighbors.  \n",
    "   - This ensures new samples respect the cluster’s structure.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Key Parameters\n",
    "- **kmeans_k**  \n",
    "  - Number of clusters.  \n",
    "  - Larger **kmeans_k** → finer segmentation of data.  \n",
    "  - Helps focus oversampling on local minority “pockets.”  \n",
    "\n",
    "- **cluster_balance_threshold**  \n",
    "  - Decides when a cluster is eligible for oversampling.  \n",
    "  - Example:  \n",
    "    - **0.1** → clusters with ≥10% minority get oversampled.  \n",
    "    - **0.0** → every cluster is oversampled, even majority-heavy ones.  \n",
    "\n",
    "- **density_exponent**  \n",
    "  - Controls how density affects oversampling.  \n",
    "  - **\"auto\"** = based on number of features.  \n",
    "  - Higher values → denser clusters get more synthetic points.  \n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "KMeans-SMOTE = SMOTE with clustering.  \n",
    "It oversamples **more in minority-heavy clusters** and **less in majority-heavy clusters**, producing balanced and realistic synthetic samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e653310-c47f-416d-bcd5-83a5cf106bcc",
   "metadata": {},
   "source": [
    "## Comparison of SMOTE Variants\n",
    "\n",
    "- **No SMOTE (Baseline):**  \n",
    "  The dataset stays highly imbalanced. The model struggles to learn minority (fraud) patterns and tends to predict majority (non-fraud) more often.\n",
    "\n",
    "- **SMOTE (Regular):**  \n",
    "  Creates synthetic samples by interpolating between minority neighbors. This balances the dataset and improves recall, but sometimes generates less realistic points in sparse regions.\n",
    "\n",
    "- **Random Oversampling (ROS):**  \n",
    "  Duplicates existing minority class samples until the dataset is balanced.  \n",
    "  Simple and effective for balancing.  \n",
    "  Risk of **overfitting**, since no new information is added.\n",
    "- **Borderline-SMOTE:**  \n",
    "  Focuses on samples near the decision boundary (danger zone).  \n",
    "  - **Borderline-1:** Generates minority samples near the boundary.  \n",
    "  - **Borderline-2:** Generates even “harder” minority samples closer to majority, making the model better at detecting fraud in tricky regions.\n",
    "\n",
    "- **KMeans-SMOTE:**  \n",
    "  Uses clustering to decide where to add samples. More samples are generated in clusters with higher imbalance (minority density). This avoids over-sampling “easy” areas and produces more diverse, useful samples.\n",
    "\n",
    "### Takeaway\n",
    "- **ROS** → Quick fix, but prone to overfitting.  \n",
    "- **SMOTE** → Good starting point, creates synthetic variation.  \n",
    "- **Borderline-SMOTE** → Strengthens decision boundaries, especially for fraud detection.  \n",
    "- **KMeans-SMOTE** → Most adaptive, balances intelligently based on data distribution.  \n",
    "\n",
    "Overall, all methods improve over baseline, but **Borderline and KMeans-SMOTE provide the most realistic and effective improvements** for imbalanced fraud datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13c5d3-619a-4693-bc0d-fbbf882534ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
